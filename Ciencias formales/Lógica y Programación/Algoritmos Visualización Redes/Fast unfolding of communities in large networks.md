---
"Fecha_creacion:": 2025-07-24
"Ultima_modificacion:": 2025-07-24
"Nombre_documento:": Fast unfolding of communities in large networks
"Tipo_documento:": Artículo
"tipo:": Reseña corta
"autor:": Vincent D. Blonde, Jean-Loup Guillaume , Renaud Lambiotte and Etienne Lefebvre
"Link:": https://arxiv.org/pdf/0803.0476
---
Este algoritmo fue diseñado para **extraer particiones heurísticamente relevantes de grandes redes**. La urgencia de encontrar formas computacionalmente eficientes de encontrar tales comunidades tiene que ver con el rápido crecimiento de información compleja que combina organización y aleatoriedad en nuestra sociedad. En la literatura podemos encontrar la existencia de varios tipos de algoritmos que intentan dar una solución a este tipo de redes cada vez más complejas: algoritmos de división, algoritmos de aglomeración y métodos de optimización; la manera en cómo podemos evaluar la capacidad de estos algoritmos para señalar comunidades se da a través del concepto de [[Exploratory network analysis with Pajek#técnica de optimización|modularidad]], el cual indica en un valor escalar entre -1 y 1  la densidad de las aristas al interior de la comunidad respecto a las aristas entre las comunidades. Las comunidades por lo tanto son conjuntos de nodos más interconectados al interior de la comunidad que entre las comunidades. La innovación de este método consiste en un proceso llamado *pass* que consta de dos pasos: 

1) para cada nodo $i$ consideramos los vecinos $j$ de $i$ y evaluamos la ganancia de modularidad que se produciría al eliminar $i$ de su comunidad y colocarlo en la comunidad de $j$. El nodo $i$ se coloca entonces en la comunidad para la que esta ganancia es máxima (en caso de empate utilizamos una regla de desempate), pero solo si esta ganancia es positiva. Si no es posible obtener una ganancia positiva, $i$ permanece en su comunidad original. Este proceso se aplica de forma repetida y secuencial para todos los nodos hasta que no se puede lograr ninguna mejora adicional y, entonces, se completa la primera fase
2) La segunda fase del algoritmo consiste en construir una nueva red cuyos nodos son ahora las comunidades encontradas durante la primera fase. Para ello, los pesos de los enlaces entre los nuevos nodos vienen dados por la suma del peso de los enlaces entre los nodos de las dos comunidades correspondientes. Los enlaces entre nodos de la misma comunidad dan lugar a bucles propios para esta comunidad en la nueva red. Una vez completada esta segunda fase, es posible volver a aplicar la primera fase del algoritmo a la red ponderada resultante e iterar

El algoritmo se detiene hasta que no sea posible aplicar más cambios para aumentar el grado de modularidad de la red. En testeos que los investigadores han llevado a cabo con grandes redes el número de iteraciones de *pass* no supera la quinta vez, los investigadores advierten, por tanto, que el mayor consumo de computación y memoria[^1] sucede en la primera iteración. Debemos anotar que cada iteración *pass* genera una red con comunidades, por lo que desde una perspectiva jerárquica cada partición intermedia representa un nivel de análisis independiente de modularidad máxima, esto permite observar los resultados a través de diferentes resoluciones que se adapten a nuestro interés de investigación.

Los resultados obtenidos al comparar este algoritmos con otros disponibles indican un gran rendimiento en grandes redes de millones de nodos, no obstante, para cerciorar de que el rápido rendimiento no significa una pérdida de precisión en la detección de comunidad, los investigadores sometieron el algoritmo a red de telefonía belga con varios millones de nodos y compararon el resultado con datos adicionales referentes a la lengua materna de los clientes, el resultado arrojó comunidades (261) donde mayoritariamente había una tendencia hacia el monolingüismo, confirmando con este testeo y otros que se detallan en el paper la capacidad heurística de este algoritmo incluso con redes de tamaños enormes.  
# Footnotes

[^1]: el límite de capacidad de procesamiento del algoritmo está determinado por la cantidad de memoria RAM de un dispositivo